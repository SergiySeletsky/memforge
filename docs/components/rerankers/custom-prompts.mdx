---
title: Custom Prompts
---

When using LLM rerankers, you can customize the prompts used for ranking to better suit your specific use case and domain.

## Default Prompt

The default LLM reranker prompt is designed to be general-purpose:

```
Given a query and a list of memory entries, rank the memory entries based on their relevance to the query.
Rate each memory on a scale of 1-10 where 10 is most relevant.

Query: {query}

Memory entries:
{memories}

Provide your ranking as a JSON array with scores for each memory.
```

## Custom Prompt Configuration

You can provide a custom prompt template when configuring the LLM reranker.

## Prompt Variables

Your custom prompt can use the following variables:

| Variable         | Description                           |
| ---------------- | ------------------------------------- |
| `{query}`        | The search query                      |
| `{memories}`     | The list of memory entries to rank    |
| `{user_id}`      | The user ID (if available)            |
| `{user_context}` | Additional user context (if provided) |

## Best Practices

1. **Be Specific**: Clearly define what makes a memory relevant for your use case
2. **Use Examples**: Include examples in your prompt for better model understanding
3. **Structure Output**: Specify the exact JSON format you want returned
4. **Test Iteratively**: Refine your prompt based on actual ranking performance
5. **Consider Token Limits**: Keep prompts concise while being comprehensive

## Prompt Testing

You can test different prompts by comparing ranking results.

## Common Issues

- **Too Long**: Keep prompts under token limits for your chosen LLM
- **Too Vague**: Be specific about ranking criteria
- **Inconsistent Format**: Ensure JSON output format is clearly specified
- **Missing Context**: Include relevant variables for your use case
