---
title: Reranker-Enhanced Search
description: Boost relevance by reordering vector hits with reranking models.
icon: "ranking-star"
---

Reranker-enhanced search adds a second scoring pass after vector retrieval so Mem0 can return the most relevant memories first. Enable it when keyword similarity alone misses nuance or when you need the highest-confidence context for an agent decision.

<Info>
  **You’ll use this when…**
  - Queries are nuanced and require semantic understanding beyond vector distance.
  - Large memory collections produce too many near matches to review manually.
  - You want consistent scoring across providers by delegating ranking to a dedicated model.
</Info>

<Warning>
  Reranking raises latency and, for hosted models, API spend. Benchmark with production traffic and define a fallback path for latency-sensitive requests.
</Warning>

---

## Feature anatomy

- **Initial vector search:** Retrieve candidate memories by similarity.
- **Reranker pass:** A specialized model scores each candidate against the original query.
- **Reordered results:** Mem0 sorts responses using the reranker’s scores before returning them.
- **Optional fallbacks:** Toggle reranking per request or disable it entirely if performance or cost becomes a concern.

<AccordionGroup>
  <Accordion title="Supported providers">
    - **[Cohere](/components/rerankers/models/cohere)** – Multilingual hosted reranker with API-based scoring.  
    - **[Sentence Transformer](/components/rerankers/models/sentence_transformer)** – Local Hugging Face cross-encoders for GPU or CPU.  
    - **[Hugging Face](/components/rerankers/models/huggingface)** – Bring any hosted or on-prem reranker model ID.  
    - **[LLM Reranker](/components/rerankers/models/llm_reranker)** – Use your preferred LLM (OpenAI, etc.) for prompt-driven scoring.  
    - **[Zero Entropy](/components/rerankers/models/zero_entropy)** – High-quality neural reranking tuned for retrieval tasks.
  </Accordion>
  <Accordion title="Provider comparison">
    | Provider | Latency | Quality | Cost | Local deploy |
    | --- | --- | --- | --- | --- |
    | Cohere | Medium | High | API cost | ❌ |
    | Sentence Transformer | Low | Good | Free | ✅ |
    | Hugging Face | Low–Medium | Variable | Free | ✅ |
    | LLM Reranker | High | Very high | API cost | Depends |
  </Accordion>
</AccordionGroup>

---

## Configure it

### Basic setup

```typescript
import { Memory } from 'mem0ai/oss';

const config = {
  reranker: {
    provider: 'cohere',
    config: {
      model: 'rerank-english-v3.0',
      apiKey: process.env.COHERE_API_KEY || '',
    },
  },
};

const m = new Memory(config);
```

<Info icon="check">
  Confirm `results["results"][0]["score"]` reflects the reranker output—if the field is missing, the reranker was not applied.
</Info>

<Tip>
  Set `top_k` to the smallest candidate pool that still captures relevant hits. Smaller pools keep reranking costs down.
</Tip>

### Provider-specific options

```typescript
// Cohere reranker
const config = {
  reranker: {
    provider: 'cohere',
    config: {
      model: 'rerank-english-v3.0',
      apiKey: process.env.COHERE_API_KEY || '',
      topK: 10,
      returnDocuments: true,
    },
  },
};

// Sentence Transformer reranker
const config = {
  reranker: {
    provider: 'sentence_transformer',
    config: {
      model: 'cross-encoder/ms-marco-MiniLM-L-6-v2',
      device: 'cuda',
      maxLength: 512,
    },
  },
};

// Hugging Face reranker
const config = {
  reranker: {
    provider: 'huggingface',
    config: {
      model: 'BAAI/bge-reranker-base',
      device: 'cuda',
      batchSize: 32,
    },
  },
};

// LLM-based reranker
const config = {
  reranker: {
    provider: 'llm_reranker',
    config: {
      llm: {
        provider: 'openai',
        config: {
          model: 'gpt-4',
          apiKey: process.env.OPENAI_API_KEY || '',
        },
      },
      topK: 5,
    },
  },
};
```

<Note>
  Keep authentication keys in environment variables when you plug these configs into production projects.
</Note>

### Full stack example

```typescript
const config = {
  vectorStore: {
    provider: 'qdrant',
    config: { host: 'localhost', port: 6333 },
  },
  llm: {
    provider: 'openai',
    config: { model: 'gpt-4', apiKey: process.env.OPENAI_API_KEY || '' },
  },
  embedder: {
    provider: 'openai',
    config: { model: 'text-embedding-3-small', apiKey: process.env.OPENAI_API_KEY || '' },
  },
  reranker: {
    provider: 'cohere',
    config: {
      model: 'rerank-english-v3.0',
      apiKey: process.env.COHERE_API_KEY || '',
      topK: 15,
      returnDocuments: true,
    },
  },
};

const m = new Memory(config);
```

<Info icon="check">
  A quick search should now return results with both vector and reranker scores, letting you compare improvements immediately.
</Info>

### Async support

```typescript
const results = await m.search('What are my preferences?', { userId: 'alice' });
```

<Info icon="check">
  Inspect the async response to confirm reranking still applies; the scores should match the synchronous implementation.
</Info>

### Tune performance and cost

```typescript
// GPU-friendly local reranker configuration
const config = {
  reranker: {
    provider: 'sentence_transformer',
    config: {
      model: 'cross-encoder/ms-marco-MiniLM-L-6-v2',
      device: 'cuda',
      batchSize: 32,
      topK: 10,
      maxLength: 256,
    },
  },
};

// Smart toggle for hosted rerankers
async function smartSearch(query: string, userId: string, useRerank?: boolean) {
  const shouldRerank = useRerank ?? query.split(' ').length > 3;
  return m.search(query, { userId, rerank: shouldRerank });
}
```

<Tip>
  Use heuristics (query length, user tier) to decide when to rerank so high-signal queries benefit without taxing every request.
</Tip>

### Handle failures gracefully

```typescript
try {
  results = await m.search('test query', { userId: 'alice', rerank: true });
} catch (exc) {
  console.error(`Reranking failed: ${exc}`);
  results = await m.search('test query', { userId: 'alice', rerank: false });
}
```

<Warning>
  Always fall back to vector-only search—dropped queries introduce bigger accuracy issues than slightly less relevant ordering.
</Warning>

---

## See it in action

### Basic reranked search

```typescript
const results = await m.search('What are my food preferences?', { userId: 'alice' });

for (const result of results.results) {
  console.log(`Memory: ${result.memory}`);
  console.log(`Score: ${result.score}`);
}
```

<Info icon="check">
  Expect each result to list the reranker-adjusted score so you can compare ordering against baseline vector results.
</Info>

### Toggle reranking per request

```typescript
const resultsWithRerank = await m.search('What movies do I like?', {
  userId: 'alice',
  rerank: true,
});

const resultsWithoutRerank = await m.search('What movies do I like?', {
  userId: 'alice',
  rerank: false,
});
```

<Tip>
  Log the reranked vs. non-reranked lists during rollout so stakeholders can see the improvement before enforcing it everywhere.
</Tip>

<Info icon="check">
  You should see the same memories in both lists, but the reranked response will reorder them based on semantic relevance.
</Info>

### Combine with metadata filters

```typescript
const results = await m.search('important work tasks', {
  userId: 'alice',
  filters: {
    AND: [
      { category: 'work' },
      { priority: { gte: 7 } },
    ],
  },
  rerank: true,
  limit: 20,
});
```

<Info icon="check">
  Verify filtered reranked searches still respect every metadata clause—reranking only reorders candidates, it never bypasses filters.
</Info>

### Real-world playbooks

#### Customer support

```typescript
import { Memory } from 'mem0ai/oss';

const config = {
  reranker: {
    provider: 'cohere',
    config: {
      model: 'rerank-english-v3.0',
      apiKey: process.env.COHERE_API_KEY || '',
    },
  },
};

const m = new Memory(config);

const results = await m.search('customer having login issues with mobile app', {
  agentId: 'support_bot',
  filters: { category: 'technical_support' },
  rerank: true,
});
```

<Info icon="check">
  Top results should highlight tickets matching the login issue context so agents can respond faster.
</Info>

#### Content recommendation

```typescript
const results = await m.search('science fiction books with space exploration themes', {
  userId: 'reader123',
  filters: { content_type: 'book_recommendation' },
  rerank: true,
  limit: 10,
});

for (const result of results.results) {
  console.log(`Recommendation: ${result.memory}`);
  console.log(`Relevance: ${result.score.toFixed(3)}`);
}
```

<Info icon="check">
  Expect high-scoring recommendations that match both the requested theme and any metadata limits you applied.
</Info>

#### Personal assistant

```typescript
const results = await m.search(
  'What restaurants did I enjoy last month that had good vegetarian options?',
  {
    userId: 'foodie_user',
    filters: {
      AND: [
        { category: 'dining' },
        { rating: { gte: 4 } },
        { date: { gte: '2024-01-01' } },
      ],
    },
    rerank: true,
  }
);
```

<Tip>
  Reuse this pattern for other lifestyle queries—swap the filters and prompt text without changing the rerank configuration.
</Tip>

<Note>
  Each workflow keeps the same `m.search(...)` signature, so you can template these queries across agents with only the prompt and filters changing.
</Note>

---

## Verify the feature is working

- Inspect result payloads for both `score` (vector) and reranker scores; mismatched fields indicate the reranker didn’t execute.
- Track latency before and after enabling reranking to ensure SLAs hold.
- Review provider logs or dashboards for throttling or quota warnings.
- Run A/B comparisons (rerank on/off) to validate improved relevance before defaulting to reranked responses.

---

## Best practices

1. **Start local:** Try Sentence Transformer models to prove value before paying for hosted APIs.
2. **Monitor latency:** Add metrics around reranker duration so you notice regressions quickly.
3. **Control spend:** Use `top_k` and selective toggles to cap hosted reranker costs.
4. **Keep a fallback:** Always catch reranker failures and continue with vector-only ordering.
5. **Experiment often:** Swap providers or models to find the best fit for your domain and language mix.

---

<CardGroup cols={2}>
  <Card title="Configure Rerankers" icon="sliders" href="/components/rerankers/config">
    Review provider fields, defaults, and environment variables before going live.
  </Card>
  <Card title="Build a Custom LLM Reranker" icon="sparkles" href="/components/rerankers/models/llm_reranker">
    Extend scoring with prompt-tuned LLM rerankers for niche workflows.
  </Card>
</CardGroup>
